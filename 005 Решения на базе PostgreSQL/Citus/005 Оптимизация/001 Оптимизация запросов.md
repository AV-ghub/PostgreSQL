### [Шардирование таблиц](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#table-distribution-and-shards)
В качестве поля для шардирования выбираем то что либо
* участвует в объединениях
* используется в фильтрах

Это позволяет исключить неиспользуемые шарды. 
Кроме того, Citus делегитрует вычисления на рабочие узлы, распределяя нагрузку и сокращая сетевой трафик.

### [Оптимизация рабочих узлов](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#postgresql-tuning)
Узлы представляют собой ничто иное как просто экземпляры PG. Координатор распределяет запросы для параллельного прцессинга по узлам, а узлы в свою очередь просто работают в качестве отдельного экземпляра.
Сооотв к ним относится все что касается оптимизации PG.

#### [Техника оптимизации](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#postgresql-tuning)
Пускаем запрос на основном узле
```
EXPLAIN VERBOSE
 SELECT...
```
Собираем план. в котором будет присутствовать контекстный запрос со всеми контекстными объектами узла.
Далее идем с этим запросом на узел и оптимизируем его. Далее пропагандируем оптимизацию на все узлы.

Чтобы увидеть всю картину по всем узлам, ставим флаг
```
SET citus.explain_all_tasks = 1;
```
После чего получаем разворотку EXPLAIN по всем узлам.
реальное положение узнаем при помощи EXPLAIN ANALYZE, которая сортирует планы по убыванию времени выполнения. а без разворотки (citus.explain_all_tasks = 0) показывает самый длительный план.

> Разница в выполнении может быть из-за железа, конфигурации или локальных перекосов данных.

#### [Масштабирование производительности](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#scaling-out-performance)
В идеале правильное шардирование должно привести к возможности выполнения запросов на отдельной шарде **в пределах** имеющейся там **оперативнгой памяти**. При нехватке ее под текущие задачи рекомендуется испотльзовать **хотя бы SSD**.
При распределении точечных запросов на шарды, речь, как правило, идет про **рандомное чтение**, и HDD здесь дает наихудшие показатели.

Кроме того, если речь идет про интенсив в плане вычислений, следует рассмотреть вопрос наращивания ядер **CPU**.

Следующим моментом является тема параллелизма. Для достижения его статистически приемлемого уровня, необходимо на каждой рабочей ноде создавать **количество шард**, не меньшее **количества ядер CPU**. И принимать во внимание, что часть шард при запросах будет игнорироваться. Здесь тонкий момент средне статистического попадания в оптимальное значение.

#### [Распределенный тюнинг](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#distributed-query-performance-tuning)




















