## [Шардирование таблиц](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#table-distribution-and-shards)
В качестве поля для шардирования выбираем то что либо
* участвует в объединениях
* используется в фильтрах

Это позволяет исключить неиспользуемые шарды. 
Кроме того, Citus делегитрует вычисления на рабочие узлы, распределяя нагрузку и сокращая сетевой трафик.

## [Оптимизация рабочих узлов](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#postgresql-tuning)
Узлы представляют собой ничто иное как просто экземпляры PG. Координатор распределяет запросы для параллельного процессинга по узлам, а узлы в свою очередь просто работают в качестве отдельного экземпляра.
Сооотв к ним относится все что касается оптимизации PG.

### [Техника оптимизации](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#postgresql-tuning)
Пускаем запрос на основном узле
```
EXPLAIN VERBOSE
 SELECT...
```
Собираем план. в котором будет присутствовать контекстный запрос со всеми контекстными объектами узла.
Далее идем с этим запросом на узел и оптимизируем его. Далее пропагандируем оптимизацию на все узлы.

Чтобы увидеть всю картину по всем узлам, ставим флаг
```
SET citus.explain_all_tasks = 1;
```
После чего получаем разворотку EXPLAIN по всем узлам.
реальное положение узнаем при помощи EXPLAIN ANALYZE, которая сортирует планы по убыванию времени выполнения. а без разворотки (citus.explain_all_tasks = 0) показывает самый длительный план.

> Разница в выполнении может быть из-за железа, конфигурации или локальных перекосов данных.

### [Масштабирование производительности](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#scaling-out-performance)
В идеале правильное шардирование должно привести к возможности выполнения запросов на отдельной шарде **в пределах** имеющейся там **оперативнгой памяти**. При нехватке ее под текущие задачи рекомендуется использовать **хотя бы SSD**.
При распределении точечных запросов на шарды, речь, как правило, идет про **рандомное чтение**, и HDD здесь дает наихудшие показатели.

Кроме того, если речь идет про интенсив в плане вычислений, следует рассмотреть вопрос наращивания ядер **CPU**.

Следующим моментом является тема параллелизма. Для достижения его статистически приемлемого уровня, необходимо на каждой рабочей ноде создавать **количество шард**, не меньшее **количества ядер CPU**. И принимать во внимание, что часть шард при запросах будет игнорироваться. Здесь тонкий момент средне-статистического попадания в оптимальное значение.

## [Распределенный тюнинг](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#distributed-query-performance-tuning)
Первоначально необхлодимо пустить запрос на координаторе и соотв его часть на рабочем узле (установив **\timing**). Это даст представление о проблемах на собственно распределенном запросе.
Далее тюнинг рассматриваем в двух частях - основной и расширенный.

### [Основной](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#general)
С учетом распределения данных по шардам, увеличение потоков вставки в целом сильно повышает общий уровень вставки (также видимо в связи с неактуальностью PK на распределенной схеме).

Особое внимание следует уделять конструкции подзапросов и CTE.

> По всей видимости это самое больное место распределенных вычислений.

Необходимо всячески избегать [Subquery/CTE Push-Pull Execution](https://docs.citusdata.com/en/v12.0/develop/reference_processing.html#subquery-cte-push-pull-execution)
Для этих целей стараться колоцировать данные, используемые в подзапросах, чтобы они могли четко делегироваться для выполнения на узлах, имея полный набор необходимых данных в пределах узла.

В случае, если это невозможно, стараться минимизировать как возвращаемый из подзапроса на координатор массив данных, так и количество рабочих узлов, на которые будет пропагандироваться в итоге результат подзапроса.

В случае колоцирования данных CTE, рекомендуется использовать технику его материализации ([1](https://postgrespro.ru/docs/postgresql/16/queries-with#QUERIES-WITH-CTE-MATERIALIZATION) [2](https://www.postgresql.org/docs/current/queries-with.html#QUERIES-WITH-CTE-MATERIALIZATION)). Когда запрос CTE встраивается в родительский (использующий результаты CTE) запрос и т.о. может выполнять фильтрованную родительским запросом часть на соотв рабочем узле (разумеется, как указывалось выше, при условии колоцирования данных подзапроса).

### [Расширенный](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#advanced)
#### [Пул соединений](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#connection-management)
* [citus.max_adaptive_executor_pool_size (integer)](https://docs.citusdata.com/en/v12.0/develop/api_guc.html#max-adaptive-executor-pool-size) очень похож по сути на MAXDOP. Отсюда рекомендации по его применению - 1-2 для коротких запросов, до 16 для аналитических.
* Обратно [citus.executor_slow_start_interval (integer)](https://docs.citusdata.com/en/v12.0/develop/api_guc.html#executor-slow-start-interval) взвинчиваем для коротких запросов, чтобы неповадно было открывать новые соединения и увеличивать параллелизм, и наоборот, умеьшаем для заведомо тяжелых запросов, чтобы пул параллелился сразу.
* [citus.max_cached_conns_per_worker (integer)](https://docs.citusdata.com/en/v12.0/develop/api_guc.html#max-cached-conns-per-worker) сооотв имеет смысл держать для бомбардирующих запросов. Аналитике можно дать развернуться на низком citus.executor_slow_start_interval (integer), а штучным OLTP кэш не нужен.
* [citus.max_shared_pool_size (integer)](https://docs.citusdata.com/en/v12.0/develop/api_guc.html#citus-max-shared-pool-size-integer) рекомендуется ставить значительно выше max_connections limit, поскольку есть ряд операций, которые не ориентируются на параметры лимита соединений. Кроме того, есть процессы репартиционирования, которые тоже никого не спрашивая забирают себе соединения из пула. Таким образом, при низком значении мы можем начать штабелями ронять запросы на сильной нагрузке.

#### [Политика распределения задач по раблочим узлам](https://docs.citusdata.com/en/v12.0/performance/performance_tuning.html#task-assignment-policy)
В зависимости от целей и существующей конфигурации есть три варианта распределения.
##### Greedy
Равномерное распределение по всем узлам. Подходит для большинства задач.
##### Round-robin
Применяется, когда количество шард относительно мало в сравнении с количеством рабочих узлов.
Позволяет лучше утилизировать ресурсы кластера.
##### First-replica
Задачи узлам назначаются в соответствии с логическим порядком использования шард, и соотв их расположения на узлах.
Это гарантирует нахождение в памяти на всех задействованных узлах горячих данных, используемых в контексте выполняемого цельного распределенного запроса.

#### Формат обмена промежуточными данными
По умолчанию Citus передает данные с узлов в текстовом формате. Сериализация и десериализация в этом случае достаточно накладная.
На версиях PG выше 13 можно включить бинарный формат сериализации, что значительно дешевле.
Включается он парметром конфигурации [citus.binary_worker_copy_format (boolean)](https://docs.citusdata.com/en/v12.0/develop/api_guc.html#binary-worker-copy-format)















